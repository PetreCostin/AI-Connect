# IBM watsonx Configuration
# Get your API key from: https://cloud.ibm.com/iam/apikeys
WATSONX_API_KEY=your_watsonx_api_key_here

# watsonx Project ID (required)
# Get from your watsonx.ai project settings
WATSONX_PROJECT_ID=your_project_id_here

# watsonx API URL (default for IBM Cloud US-South region)
WATSONX_URL=https://us-south.ml.cloud.ibm.com

# watsonx Model ID (the AI model to use)
# Options: meta-llama/llama-3-70b-instruct, ibm/granite-13b-chat-v2, etc.
WATSONX_MODEL_ID=meta-llama/llama-3-70b-instruct

# Server Configuration
PORT=5000
NODE_ENV=development

# CORS Configuration (comma-separated allowed origins)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5000

# Rate Limiting (requests per window)
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
